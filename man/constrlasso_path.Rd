% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/constrlasso.R
\name{constrlasso_path}
\alias{constrlasso_path}
\title{The function constrlasso_path}
\usage{
constrlasso_path(
  X,
  y,
  Aeq = NULL,
  beq = NULL,
  A = NULL,
  b = NULL,
  penidx = NULL,
  init_method = "QP",
  epsilon = 1e-04,
  stop_lambda_tol = 1e-07,
  ceiling_tol = 1e-10,
  zeros_tol = 1e-20,
  verbose = FALSE
)
}
\arguments{
\item{X}{an nxp matrix with p regressors with n observations.}

\item{y}{an nx1 response vector with n observations.}

\item{Aeq}{a cxp equality constraint matrix, containing c constraints for p regressors.
Default value is Aeq=NULL, no equality constraints.}

\item{beq}{a cx1 equality constraint vector. Default value is beq=NULL, no equality constraints.}

\item{A}{a cxp inequality constraint matrix, containing c constraints for p regressors.
Default value is A=NULL, no inequality constraints.}

\item{b}{a cx1 inequality constraint vector. Default value is b=NULL, no inequality constraints.}

\item{penidx}{a logical px1 vector, indicating which coefficients are to be penalized.
Default value is penidx=NULL and allows all p coefficients to be penalized.}

\item{init_method}{a character string, the initializing method to be used.
Possible values are "QP" (default) for Quadratic Programming and "LP" for Linear Programming.
"LP" is recommended only when it's reasonable to assume that all coefficient estimates initialize at zero.}

\item{epsilon}{a tuning parameter for ridge penalty in case of high-dimensional (n>p) regressors matrix X.
Default value is 1e-4.}

\item{stop_lambda_tol}{a tolerance value for the tuning lasso parameter.
The algorithm stops when hitting this tolerance. Default value is 1e-7.}

\item{ceiling_tol}{a tolerance value for the change in subgradients. Default value is 1e-10.}

\item{zeros_tol}{a tolerance value for the zero equality of coefficients. Default value is 1e-20.}

\item{verbose}{a logical parameter. TRUE prints along the constraint lasso solution path. Default value is FALSE.}
}
\value{
lambda_path a vector of the tuning parameter values along the solution path.

beta_path  a matrix with estimated regression coefficients for each value of lambda_path

df_path a vector with degrees of freedom along the solution path

objval_path a vector with values of the objective function for each value of lambda_path
}
\description{
This function performs a Constrained Lasso Solution Path
as in \insertCite{gaines2018algorithms;textual}{constrlasso}.
It computes the solution path for the constrained lasso problem, using a predictor matrix X and a response y.
The constrained lasso solves the standard lasso \insertCite{tibshirani1996regression;textual}{constrlasso}
subject to the linear equality constraints \eqn{Aeq \beta = beq}
and linear inequality constraints \eqn{A \beta \le b}.
The result lambda_path contains the values of the tuning parameter along the solution path and beta_path -
the estimated regression coefficients for each value of lambda_path.
The function corresponds to lsq_classopath of the SparseReg MATLAB-toolbox of by Zhou and Gaines,
see \href{http://hua-zhou.github.io/SparseReg/}{the project page}.
For more information, see \href{http://hua-zhou.github.io/media/pdf/GainesKimZhou08CLasso.pdf}{\insertCite{gaines2018algorithms;textual}{constrlasso}}.
}
\section{Details}{

The Constrained Lasso as in \insertCite{gaines2018algorithms;textual}{constrlasso} minimizes
\deqn{0.5||y - X \beta ||^2_2 + \lambda||\beta||_1,}
subject to \eqn{Aeq \beta = beq} and \eqn{A \beta\le b}.
}

\examples{

library(constrlasso)
set.seed(1234)
n <- 200
p <- 50
Xmat <- matrix(, n, p)
for (i in 1:p) {
  Xmat[, i] <- rnorm(n, runif(1, -3, 3), runif(1, 1, 2))
}
betas <- runif(p, -2, 2)
nonzeros <- sample(1:p, 20, replace = FALSE)
yvec <- Xmat[, nonzeros] \%*\% betas[nonzeros] + rnorm(n, 0, 2)
classopath_results <- constrlasso_path(Xmat, yvec)

}
\references{
\insertAllCited
}
